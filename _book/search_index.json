[
["index.html", "CI 5371: Learning Analytics About", " CI 5371: Learning Analytics Bodong Chen 2020-10-19 About This is the course website of CI 5371 - Learning Analytics: Theory and Practice offered in Fall ’20 at the University of Minnesota. This course is fully online. All content published on this website is open to the public. Instructor: Bodong Chen, Associate Professor in Learning Technologies and Huebner Endowed Chair in Education &amp; Technology. Important Links Syllabus (public) Slack community (invitation only) Hypothes.is private group (invitation only) Twitter hashtag #LAUMN (public) "],
["intro.html", "Week 1 Introduction 1.1 This Course 1.2 Week 1 Activities", " Week 1 Introduction A warm welcome to CI 5371 - Learning Analytics: Theory and Practice! I am so excited to offer this course again this fall at the University of Minnesota. As the instructor, I learn so much from the class community each year and look forward to our adventure together this semester! This week we will: Get familiar with the course, including its design, schedule, and tools Get to know each other Discuss our diverse interests in learning analytics 1.1 This Course 1.1.1 Course Syllabus First thing first, please read the course syllabus in its entirety. Leave a comment or send me an email when you have any questions. 1.1.2 Technology setup An online course does not need to be about watching videos and answering quizzes. To foster rich learning experiences, we will be using several technological tools to foster social, collaborative learning. Depending on your familiarity with these tools, there could be a learning curve. So please spend time this week to familiarize yourself with them. Pro tip: Please use you UMN id (chenbd for myself) consistently when signing up for these tools. Zoom. We will host a number of virtual meetings on Zoom throughout the semester. Please make sure your computer has Zoom installed (see the video below). Please test your Zoom setup in advance to make sure audio and video configurations work properly. Slack. You will receive a link that invites you to join our Slack community. Course announcements are made on Slack. All sorts of class discussions will take place there as well. You can also interact with our course alumni in some public channels. Slack is a better tool for social interaction and community building. First time using Slack? Watch the video below and/or read this brief introduction to Slack. Hypothes.is. You should have received a link that invites you to join our Hypothes.is group. Hypothes.is is a web annotation tool that enables us to discuss readings in a contextual manner. When annotating, please make sure our group name (LAUMN-2020) is properly selected (see image below). See this quick start guide to get started, and this tutorial page to learn about annotating together as a group. Again, please use your UMN id when creating your Slack and Hypothesi.is account. If you have any feedback on the design, I’d love to hear your thoughts. 1.1.3 What to expect each week? This online class is designed to offer rich opportunities for social participation. Below is an infographic showing how a week would (typically) look like. Our class meetings happen on Tuesdays. The class meetings are designed for us to chat about things we’ve learned, gaps of understanding, future plans, etc. In some weeks we will meet in Zoom; in some other weeks, we will “meet” on Slack throughout Tuesday. A fresh week starts on Wednesdays. Depending on your schedule, you can get started with course readings and begin to make annotations. By the end of Friday, you are expected to finish reading articles assigned for the week and post your personal annotations on Hypothesis. By the end of Monday, you are expected to check out what other colleagues annotated and reply to each other. You will receive an email notification when someone responds to you. It is hoped that by putting our minds together we can develop deeper understanding. On Tuesday, we chat more on Slack or Zoom. Detailed guidelines will be posted each week. 1.2 Week 1 Activities 1.2.1 Readings Course syllabus 1.2.2 Week 1 Zoom Meeting Our first virtual meeting will take place on Tuesday, 09/08, 5:30-7pm via Zoom. You should have received a calendar invitation with details. See you soon! "],
["learning-analytics-a-brief-overview.html", "Week 2 Learning Analytics: A Brief Overview 2.1 Learning Activities", " Week 2 Learning Analytics: A Brief Overview This week we will: Develop a grasp of the field of LA Start to explore course project ideas 2.1 Learning Activities 2.1.1 Read, annotate, and discuss This week, we will get a chance to take a closer look at this field by reading some introductory texts, exploring cases/examples, and posing questions. What problems do learning analytics seek to address? In which educational settings? At which levels of an education system? Because this field is truly inter–disciplinary, I expect us to enter this field from our unique backgrounds and contribute to the field with different perspectives. Please read: Siemens (2013) - download link or this link Krumm, Means, and Bienkowski (2018) - Chapter 2 (Note: This reading can only be annotated offline. Check this Youtube video to learn how.) When reading each article, please annotate wherever you like. Let the community know when something confuses you, when you find an example that fits your interests, when you find a statement illuminating/useful, etc. Please also reply to each other whenever you could. See Section 1.1.3 posted in Week 1 for details about the weekly timeline. This week, I encourage you to be very intentional about tags you use in Hypothesis annotations. Several ground rules I’d like to propose to our collective tagging to help us better index our ideas: Let’s include # in our tags (e.g., #question) Let’s use lowercase (e.g., #sharing), unless the tag is a named entity (e.g., #LMS) Let’s not include spaces, but use underscore (_) instead (e.g., #data_mining instead of #data mining) Let’s try to use the following tags when we discover #muddy_points,#good_points, and #useful_points in the readings Reminder: When annotating with Hypothes.is, please make sure the LAUMN-2020 group is selected. If you are not sure about annotating PDFs, please refer back to tutorials in Week 1. 2.1.2 Watch a Video George Siemens, who authored the first article we read, gave a lecture about learning analytics. George is the founding president of the Society for Learning Analytics Research (SoLAR), which is the most prominent international organization of learning analytics. Watch Siemens’ lecture and share your ideas on Slack. 2.1.3 Exploring course project ideas While/after reading, start to explore possible project ideas based on your interests. At this point, it is totally okay if your project idea is more or less vague. You can share your ideas on Slack. This is an opportunity for us to learn more about our interests, receive feedback, and find colleagues with similar interests. Below are a list of example project ideas. Please see the syllabus for more detailed guidelines. Applying Natural Language Processing to Investigating Language Development and Epistemic Complexity in Group Chats Integrating a Teacher Dashboard in Science Classrooms: A Mixed-Methods Study of Teacher Perspectives Developing a Deep Learning Model for the Prediction of Student Success in Introductory Physics Students under lockdown: Comparisons of students’ social networks and mental health before and during the COVID-19 crisis 2.1.4 Week 2 Zoom Meeting We will meet synchronously again on Tuesday, 09/15, 5:30-7pm via Zoom. Have a great week! References "],
["ethics-algorithmic-accountability-and-system-integrity.html", "Week 3 Ethics, Algorithmic Accountability, and System Integrity 3.1 Ethics in Learning Analytics 3.2 Week 3 Learning Activities 3.3 Housekeeping", " Week 3 Ethics, Algorithmic Accountability, and System Integrity This week we will: Develop an understanding of ethics in the context of LA Develop an awareness of theories, tools, and approaches that promote system integrity of learning analytics Continue to explore course project ideas Thanks for the engaged conversations in the first week of #LAUMN! What is apparent to myself is that the breadth of expertise represented in our community is truly energizing. I hope we can continue to have deep conversations within and beyond this community, and to engage in learning that’s personally meaningful to everyone of us. In the spirit of “living and exploring the capacity of learning analytics”, I encourage you to explore tools like CROWD LAAERS that we discussed during our Zoom meeting. After authenticating yourself using your Hypothes.is API token, you will be able to choose our group and have a bird-eye view of our annotation activities. I found the Threads section quite useful for discovering threads with more (or less) participation. You can click on a particular thread to filter or “drill down” the data. 3.1 Ethics in Learning Analytics Let’s be clear, ethics should not be an after-thought in a learning analytics application. (That’s why we are discussing ethics this week instead of in Week 14 of this semester.) But what do ethical practices in the field entail is not always clear. While research ethics considers principles such as confidentiality, privacy, and informed consent, a learning analytics project may not be considered research at all (if its goal is not to produce generalizable knowledge). However, extensive collection of learning data, increasing cases of “black-box algorithms,” and more direct impact on learners necessitate some serious conversations about ethics in learning analytics. (Photo Credit: Wikipedia) Last week’s discussions have already touched upon many questions about ethics. This week, we are going to dive into ethics, algorithmic accountability, and system integrity. 3.2 Week 3 Learning Activities 3.2.1 Read, annotate, and discuss Please read: Prinsloo and Slade (2017) - link. (Note: It may be difficult to highlight larger text snippets in this particular PDF file.) Optional readings: Kitto and Knight (2019) - link Chen and Zhu (2019) - link. When reading each article, please annotate wherever you like. Let the community know when something confuses you, when you find an example that fits your interests, when you find a statement illuminating/useful, etc. Please also reply to each other whenever you could. See Section 1.1.3 posted in Week 1 for details about the weekly timeline. This week, I encourage you to be very intentional about tags you use in Hypothesis annotations. Reminder: When annotating with Hypothes.is, please make sure the LAUMN-2020 group is selected. If you are not sure about annotating PDFs, please refer back to this video tutorial. 3.2.2 Meet Learning Analytics Experts Paul Prinsloo from the University of South Africa (Unisa) has been writing and giving talks about ‘ethics and learning analytics’ for many years. He delivered a keynote on this topic in Scotland in 2018. He has graciously allowed me to embed his slides on our course website: Zombie categories, broken data and biased algorithms: What else can go wrong? Ethics in the collection, analysis and use of student data from University of South Africa (Unisa) Simon Buckingham Shum, Director of the Connected Intelligence Centre (CIC) at the University of Technology Sydney, invited us to consider ‘Algorithmic Accountability’ and ‘Analytic System Integrity’. Discussion of Algorithmic Accountability has been taken up by important academic associations like the Association for Computing Machinery (ACM). But Simon stretches our thinking to consider ‘Analytic System Integrity’ in learning analytics. Below is a talk he gave at the UCL Institute of Education in 2016. His team is recently working on Ethical Design Critique, which offers concrete measures to enhance ethics in learning analytics tools. And he is delivering a Learning Informatics Webinar to a UMN audience on Sep 24! Don’t miss it. 3.2.3 “Living” with Learning Analytics Last week, we introduced CROWD LAAERS designed for Hypothes.is. This week, I encourage you to check out this data tool developed by a Hypothes.is engineer that helps you “see” Hypothes.is data. Again, you will need to use your Hypothes.is API token to access our private group annotations. Please try to play with the CSV and JSON formats to see what they look like. Share your thoughts and findings on Slack! 3.2.4 Continuing to explore project ideas Thanks for sharing your initial project ideas on Slack. As we read and discuss more, please take time to explore and refine ideas. The official deadline for sharing your project idea is 9/29. Please consider problems/goals, stakeholders, data sources, analysis, and action of your project. When you’re ready, please post your project idea in the projects channel. Continue to give each other’s ideas constructive comments! 3.3 Housekeeping 3.3.1 Start to Explore Special Interest Groups (SIGs) Please start to consider which Special Interest Group(s) you’re interested in. Below is a list of tentative topics but you can suggest topics beyond the list. Ideally, the Special Interest Group you sign up for is related to your final project. Social Network Analysis Predictive Models Text and Discourse Analytics Visual Learning Analytics Temporal Analytics Multimodal Learning Analytics Collaboration Analytics Institutional Readiness 3.3.2 Future Weeks No Zoom meetings in the next few weeks. There will be a Slack chat on Tue, Sep 22 (details to be announced). Questions? Reach out to Bodong via Slack or email. References "],
["cases-and-examples-of-learning-analytics.html", "Week 4 Cases and Examples of Learning Analytics 4.1 Learning Analytics Cases and Examples 4.2 Week 4 Learning Activities 4.3 Housekeeping", " Week 4 Cases and Examples of Learning Analytics This week we will: Develop familiarity with ways computational methods can be used to support research Develop familiarity with real-world learning analytics tools and applications Continue to explore course project ideas Thanks for the engaged conversations on both Hypothes.is and Slack! Great collaborative work (like this thread) as we make sense of complex ideas in course readings. Please keep it up! Two Pro Tips about Hypothes.is: If you prefer to not see existing highlights when reading an article, click on the Hide/Show Highlights button on the sidebar. You can also resize the sidebar, click and hold on the Arrow button and then drag to resize the sidebar. 4.1 Learning Analytics Cases and Examples After reading and discussing several key articles about learning analytics, I hope it is becoming clearer that there are often two types of work involved when people talk about learning analytics: Applying computational methods (or data science methods) to learning data to help us understand complex learning phenomena Designing and deploying tools that are based on computational analysis of learning data to make an impact in a learning context Researchers of learning (e.g. learning scientists) may feel more drawn to the first, while folks who engineer tools or work closely with people who make day-to-day decisions in education (e.g. teachers, advisers, students, administrators) could be more attracted to the latter. Of course, these two lines are not clear-cut but deeply intertwined. Both lines require us to think carefully about ethics, accountability, and integrity in the work, even though the considerations and coping strategies may differ between these two lines. 4.2 Week 4 Learning Activities This week, we will explore and analyze more concrete cases/examples of learning analytics. Following the distinction made above, you can purposefully target one type of work in your interest area. Use Hypothes.is as a social annotation tool for example. As a researcher, I am curious about what factors are driving our social interaction and would be interested in learning data science methods that would allow me to model social interaction. As a learning technologist, I am also interested in supporting instructors who teach online classes using Hypothes.is. What information might be useful for their decision-making? How to best present such information? And, to tell you the truth, I am actually interested in both directions! Please take time to think about your interests at this moment so that your exploration can become more targetted. 4.2.1 Meet Two Experts Before we dive into identifying and analyzing cases, I want to share two talks that are related to this week and the projects you are working on. The first talk was given by Dr. Stephanie Teasley from the University of Michigan, a powerhouse of learning analytics research &amp; practice. Teasley is a past president of SoLAR and has been leading various learning analytics efforts at UMich, including the My Learning Analytics (MyLA) project that is piloted at UMN. She gave a talk, titled “Learning Analytics: Data Science for Education”, which covers many grounds including analytics tool design and evaluation. The second talk was given by Dr. Roberto Martinez-Maldonado from Monash University, who previously worked at the Connected Intelligence Centre (CIC) of the University of Technology Sydney. This talk is about a a Multimodal Learning Analytics project in a medical education setting. You can find more details in their paper here published in the hyper-competitive CHI conference. 4.2.2 Case analysis After watching these videos, please conduct a learning analytics case analysis following these two main steps. (a) Identify Ideally, you will identify minimally one case/example potentially relevant to your project idea. I am providing only a few examples below but you should absolutely go beyond this list. Course Signals: EDUCAUSE article, LAK12 video ECoach: https://ecoach.ai.umich.edu/Welcome/ Academic Writing Analytics: https://utscic.edu.au/tools/awa/ My Learning Analytics (MyLA): https://sites.google.com/umich.edu/my-learning-analytics-help/home Yellowdig visualization tool: https://vimeo.com/169580885 (b) Analyze and Share When analyzing a case/example, please consider the following aspects: Aspects of the project Your analysis Name and links Context and stakeholders Project goals Learning constructs Data sources Data analysis/mining techniques Actions suggested or taken Ethical considerations To share your analysis with the class, please post a Slack message in the 2020-general channel with these components. To allow us to learn from each other’s work, please share your case analysis by the end of Sep 28. 4.2.3 Project ideas share-out Hope the case analysis is helpful for your exploration of project ideas. When you’re ready, please craft a blurb about your initial project idea and post it in the #projects channel. Please consider problems/goals, stakeholders, data sources, analysis, and action of your group project. Please post by the end of Sep 29. 4.3 Housekeeping 4.3.1 Continue to Explore Special Interest Groups (SIGs) Please continue to consider which Special Interest Group(s) you’re interested in. Below is a list of tentative topics but you can suggest topics beyond the list. Ideally, the Special Interest Group you sign up for is related to your final project. I will distribute a signup page next week. Social Network Analysis Predictive Models Text and Discourse Analytics Visual Learning Analytics Temporal Analytics Multimodal Learning Analytics Collaboration Analytics Institutional Readiness 4.3.2 Future Weeks No Zoom meetings in the next few weeks. Questions? Reach out to Bodong via Slack or email. "],
["theory-and-learning-analytics.html", "Week 5 Theory and Learning Analytics 5.1 Learning Analytics and Learning Theory 5.2 Week 5 Learning Activities", " Week 5 Theory and Learning Analytics Learning analytics are about learning, so theories of learning should not be ditched despite the data deluge that has been fueling the growth of learning analytics. Since the dawn of the field, there have been voices arguing for the importance of learning theory in the design, development, and implementation of learning analytics. In 2015, a special section was published by the Journal of Learning Analytics on the relation between learning theory and learning analytics. In the guest editorial, Wise and Shaffer (2015, p. 5) write: It is an exhilarating and important time for conducting research on learning, with unprecedented quantities of data available. There is danger, however, in thinking that with enough data, the numbers speak for themselves. In fact, with larger amounts of data, theory plays an ever-more critical role in analysis. The notion that theory matters even more in “big data” research in education goes against what was proposed in a controversial Wired article titled “The end of theory: The data deluge makes the scientific method obsolete” (Anderson, 2008). Now there is little disagreement that learning theory is essential for learning analytics. 5.1 Learning Analytics and Learning Theory Briefly speaking, there are essentially two ways theory is important for the field of learning analytics. 1. Theory Use in Learning Analytics As a field of research and practice, learning analytics work naturally draws from all sorts of theories. As summarized by Wise and Shaffer (2015, p. 9): Theory gives a researcher guidance about which variables to include in a model Theory gives a researcher guidance about what potential confounds, subgroups, or covariates in the data to account for Theory gives a researcher guidance as to which results to attend to Theory gives a researcher a framework for interpreting results Theory gives a researcher guidance about how to make results actionable Theory helps a researcher generalize results to other contexts and populations For example, self-regulated learning (SRL) is widely used in learning analytics and MOOC research. SRL as a learning theory has informed data collection, data transformation, data mining, and result interpretation. 2. Theory Building in Learning Analytics Even more exciting to me is the possibility of building new theories of learning and teaching, based on fine-grained data analysis enabled by advanced computational methods. Learning analytics and educational data mining research could give rise to new theories. For example, whether keystroke analysis can shed light on our understanding of writing processes? Whether temporal analysis can uncover “productive” patterns of collaborative discourse? Equally valuable are theories of learning analytics usage in emerging socio-technical contexts. For example, as new learning analytics tools are put in the hands of instructors to aid their pedagogical decisions, domain theories of analytics use can be created (e.g., van Leeuwen, 2015). After exploring cases and proposing possible project ideas last week, it is a great time for us to think about learning theory relevant to our project ideas! 5.2 Week 5 Learning Activities 5.2.1 Read, annotate, and discuss This week’s readings speak in particular to theory use in learning analytics. Reading #2 provides a concrete example of using a well-established learning theory (self-regulated learning in this case) in a research study. Reading #3 (optional) is the controversial Wired article mentioned above. Skim: Wise and Schaffer (2015) - download link. This reading is a guest editorial about learning analytics and learning theory. Please skim through it and no need to annotate closely. Read &amp; Annotate: Winne (2017) - download link. This reading discusses a very established learning theory – Self-Regulated Learning (SRL) – that is widely adopted in learning analytics. Please read and take time to “notice” how the author discusses SRL and connects SRL constructs with data. Skim: Kizilcec, Pérez-Sanagustín, and Maldonado (2017) - download link (Note: This file is accessible via the UMN Libraries.) The third reading is a study that examines SRL in MOOCs. Please skim through it to see how the authors used SRL theory to grapple with the learning phenomenon. As always, please annotate and interact as you like. Please use tags intentionally in your annotations to help you retrieve ideas potentially useful for our course projects. As a reminder, please strive to stick to the weekly participation schedule: 5.2.2 Meet Learning Analytics Experts Dr. David Williamson Shaffer is the Vilas Distinguished Professor of Learning Sciences at the University of Wisconsin-Madison. He is known for his work on game-based learning and Epistemic Network Analysis. Below is a keynote speech he delivered at the 2018 Learning Analytics and Knowledge conference in Sydney, where he summarized his idea of “quantitative ethonography” and ways to tackle theory scarcity in the age of “big data.” 5.2.3 Special Interest Group (SIG) Signup I will distribute a SIG signup form on Slack. Please fill the form with your preferred topics. As a reminder: “With support from the instructor, each SIG is expected to take a lead on designing learning activities, presenting key ideas, and facilitating discussion. Each SIG will meet with the instructor one week in advance to finalize their course plan.” (From course syllabus) Feel free to ask questions on Slack if you’re unsure about any SIG topics. 5.2.4 Continue to advance your project idea Please continue to articulate or advance your project idea. Use this week’s readings and discussions to help you more clearly conceptualize the learning phenomenon you’re interested in. Do some literature search to find out theories relevant to your project. Share in the #projects channel things you find! Have a great week! References "],
["hidden-assumptions-epistemology-pedagogy-and-assessment.html", "Week 6 Hidden Assumptions: Epistemology, Pedagogy, and Assessment 6.1 Meet An Expert 6.2 Week 6 Learning Activities", " Week 6 Hidden Assumptions: Epistemology, Pedagogy, and Assessment In this week, we will extend our dialogues on learning theory in the previous week into deeper conversations about hidden assumptions in learning analytics. This line of thinking has been informed by a talk given by Simon Knight at LAK13 titled Epistemology, Pedagogy, Assessment and Learning Analytic (see slides below). Their work has evolved over the years and one reading for this week is a book chapter with a set of provocations pushing us to think more about hidden assumptions. LAK13: Epistemology, Pedagogy, Assessment and Learning Analytics from Simon Knight I’ve written about this topic as well, in my mother tongue Chinese. To me, “Learning Analytics is like an iceberg. Its visible parts include materialized tools and observable activities, while its hidden parts comprise conceptualizations of learning, power relations in teaching and learning, and complex social, political and cultural intentions of education.” Catering to the Chinese audience, I drew on the etymology of the character 数 (n: number; v: count) in Chinese and explained how one of its ancient forms (below) is embedded with the meaning of punishing someone (esp. a kid) for their “mistakes.” I could not stop asking: To what extent is this original meaning still reflected in our use of numbers or data (数据) today? Which other assumptions and biases are built into our daily data practices in general and learning analytics in particular? How about in other languages or cultures? 6.1 Meet An Expert Last week we read the book chapter by Dr. Phil Winne, Professor from Simon Fraser University, Canada. I recently encountered this interview he did with the Centre for Change and Complexity in Learning (C3L), University of South Australia. Take a look to find out why he joined the learning analytics community and what he thinks the biggest challenges are for the field. 6.2 Week 6 Learning Activities 6.2.1 Read, annotate, and discuss We have two readings for this week – one short book chapter and one journal article. Knight and Shum (2017) - link Perrotta and Williamson (2018) - link As always, please annotate and interact as you like. As I suggested last week, you can make annotations at your own pace using your preferred medium. “I invite everyone to come up with a strategy that works for you. One example: Read through quickly and make highlights (even on paper). Then pick a few key spots to make annotations that would help yourself and others in the class.” As we work towards forming our SIGs and course projects, it would be great to think about making some of your annotations more useful for your SIG planning and final project. I encourage you to think about useful tags, e.g., #SIG_social_network, #PROJ_dental_course, and then use them to purposefully tag your annotations. By doing so, we will be able to index our ideas as we continue to engage with all sorts of resources. Again, you may choose to read through an article first and come back to annotate or tag important annotations. 6.2.2 SIG planning First of all, please finalize your Special Interest Group (SIG) choices. Feel free to ask questions on Slack. If you have assembled a group, congratulations! As for next steps, I suggest you consider the following when launching your SIG efforts: On Slack, create a new channel dedicated to your SIG. You don’t need to invite everyone yet, but you can start to chat with your SIG co-lead. Feel free to invite Bodong in to co-plan with you. 6.2.3 Continue to advance your project idea At this point, you can tell that I’m trying to structure each week for you to keep advancing your course project. Last week, treat your Slack post about learning theory as a step forward for your course project. The next few weeks will be similar. Again, it is totally fine if your current project idea still feels vague. But please do seek out opportunities to advance your ideas by searching additional resources or chatting with each other via Slack. My hope is to make sure everyone in this course is building a project that has a purpose beyond this course. You are in charge of making the final project meaningful for youself! Have a great week ahead! References "],
["educational-data-mining-an-overview.html", "Week 7 Educational Data Mining: An Overview 7.1 Meet an Expert 7.2 Week 7 Learning Activities 7.3 Bonus video: How to easily export Hypothes.is annotations?", " Week 7 Educational Data Mining: An Overview Image credit: pixabay As a sister field of Learning Analytics, Educational Data Mining (EDM) emerged a few years earlier and has its own disciplinary identity (e.g., a stonger computer science focus, its own professional society, conference, and journal). While two communities developed separately in the beginning, communication and collaboration between two communities (PDF) have increased over the years. The overlaps and differences between two communities are nicely summarized by Siemens (2013): Where LA is more concerned with sensemaking and action, educational data mining (EDM) is more focused toward developing methods for “exploring the unique types of data that come from educational settings”. Although the techniques used are similar in both fields, EDM has a more specific focus on reductionist analysis (Siemens &amp; Baker, 2012). As LA draws from and extends EDM methodologies (Bienkowski, Feng, &amp; Means, 2012, p. 14), it is a reasonable expectation that the future development of analytic techniques and tools from both communities will overlap. We are diving into EDM this week by exploring its connections with LA and playing with various data mining tools used in both communities. 7.1 Meet an Expert Candace Thille is the founding director of the Open Learning Initiative (OLI) at Carnegie Mellon University and at Stanford University. Her focus is in applying the results from research in the science of learning to the design and evaluation of open web-based learning environments and in using those environments to conduct research in human learning. She took a leave from Stanford in 2018 to work for Amazon. In this talk she gave in 2016, she explored the intersection among the science of learning, data, analytics, and technologies. 7.2 Week 7 Learning Activities 7.2.1 Read, annotate, and discuss We have two readings this week – one presenting an overview and the other introducing many useful tools. Romero and Ventura (2020) - PDF link Slater et al. (2017) - PDF link As always, please annotate and interact as you like. As we work towards forming our SIGs and course projects, it would be great to think about making some of your annotations more useful for your SIG planning and final project. I encourage you to think about useful tags, e.g., #SIG_social_network, #PROJ_dental_course, and then use them to purposefully tag your annotations. By doing so, we will be able to index our ideas as we continue to engage with all sorts of resources. Again, you may choose to read through an article first and come back to annotate or tag important annotations. Note: These tags need to used accurately (e.g. spaces and caps matter) in order to be nicely aggregated by Hypothes.is. 7.2.2 SIG Planning Since we’ve finalized our Special Interest Group plan, please create channels on Slack, invite group members in, and get the planning started. 7.2.3 Register for the next Learning Informatics Webinar I strongly encourage you to attend the next Learning Informatics Seminar on Oct 27, featuring Dr. Marcelo Worsley. RSVP here! Let the party begin! 7.3 Bonus video: How to easily export Hypothes.is annotations? Since some of you expressed an interest in using Hypothes.is in your own research, I made this short video to demonstrate my workflow. Let me know if you have any clarification questions. References "],
["all-about-data-data-wrangling.html", "Week 8 ‘All About Data,’ Data Wrangling\" 8.1 What is data wrangling? 8.2 Week 8 Learning Activities 8.3 Housekeeping for Formal Participation", " Week 8 ‘All About Data,’ Data Wrangling\" Image credit: pixabay Data wrangling, or data munging, is a critical part of any learning analytics project. It covers multiple components of the Learning Analytics Model including the collection, storage, cleaning, and integration of data (see Siemens 2013, which we read in Week 2). LA Model by Siemens Due to the quantity of data and the diversity of data sources, a learning analytics project often necessicitates data wrangling – conducted by humans – in order to transform data into actionable intelligence and systematic action (Clow, 2012). This week, we will: Familiarzie with the concept of data wrangling Play with at least one data-wrangling tool of your choice Share your data-wranglinge experiences with peers Draft a data-wrangling plan for your course project 8.1 What is data wrangling? According to Wikipedia: Data wrangling, sometimes referred to as data munging, is the process of transforming and mapping data from one “raw” data form into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics. A data wrangler is a person who performs these transformation operations. Over the past years, I have seen polls of data scientists (like this one) showing they spend 60% of their time ‘massaging’ instead of analyzing data. This percentage may even go up to 80-90% in some reports. “90% of data science is wrangling data, the other 10% is complaining about wrangling data.”(???) at #rstatsnyc — David Robinson ((???)) April 20, 2018 8.2 Week 8 Learning Activities As your course projects continue to take shape, this week provides us an opportunity to consider the data aspect and draft a Data Wrangling plan for your project. Below are activities designed for this week. 1. Watch a lecture on data wrangling This lecture was delivered by Tony Hirst to the Data, Analytics and Learning MOOC in 2014. (This video is still one of the best I could find on this topic desipte its ‘age’.) Tony is an active blogger, and his blog has always been a great source of inspiration for me. If you’re an R user, I also recommend this talk given by Stian Håklev, Sr. Engineer and Learning Architect at Minerva Project. He demonstrated almost a complete workflow going from messy, dirty Coursera data to some nice visualizations. 2. Play with one data wranging tool of your choice Our choices include – but are not limited to – the following: Spreadsheets. Yes, spreadsheets (e.g. Excel, Google Sheets) are incredibly powerful when it comes to data wrangling. Below are two tutorials that may help you unleash the power of spreadsheets. School of Data: A Gentle Introduction to Data Cleaning Data Carpentry: Data Organization in Spreadsheets OpenRefine, formerly Google Refine, “is a powerful tool for working with messy data: cleaning it; transforming it from one format into another; and extending it with web services and external data.” Its official website provides several introductory videos to get you started. There is a Data Capentry course on OpenRefine for Social Science Data. Trifacta Wrangler. This tool was created by a Stanford/Berkeley group and then lead to a company named Trifacta. Wrangler is an interactive tool for data cleaning. It takes messy, real-world data and transforms it into data tables. Then you can export to Excel, Tableau, R, etc. See this link for details. R and RStudio. If you know R basics, I strongly encourage you to spend some time on the tidyverse ecosystem. It has absolutely transformed my data wrangling practices in R. RStudio webinar on data wrangling Lynda.com course on Data wrangling with R and RStudio Python, another popular programming language among data scientists. There are plenty of tutorioals out there. Below are just two examples. Wrangling data with Pandas Wrangle Data in Jupyter Notebooks with PixieDust Rosie This list is by no means exhaustive or comprehensive. Is there a data wrangling tool you like? Please share on Slack. Not sure what data to use? Please consider exporting your Hypothes.is annotation data with the Facet tool. Finally, check out the Data Carpentry website that offers a range of lessons and workshops that you may find useful. 3. Share your journey as a Data Wrangler via Slack Yes, we can do it! How did your journey go? Have you discovered your data-wrangling superpower? Share a blurb about your journey in the #2020-general channel of Slack. If you choose to blog your experience, please post a link to your blog post to the #2020-general Slack channel. If you encounter data wrangling challenges, please also feel free to share on Slack so that we can problem solve together. 4. Craft a data-wrangling plan for your course project What implications does this week’s work have on your course project? You will be asked to share out your data-wrangling ideas on Tuesday via Slack. 8.3 Housekeeping for Formal Participation To all SIGs, please start planning your SIG activities. Our first SIG meeting is scheduled to happen on 11/3. Given it’s the election day, we may need to shift the plan. Stay tuned. Enjoy digging and wrangling! "],
["references.html", "References", " References Chen, Bodong, and Haiyi Zhu. 2019. “Towards Value-Sensitive Learning Analytics Design.” In Proceedings of the 9th International Conference on Learning Analytics &amp; Knowledge, 343–52. ACM. https://doi.org/10.1145/3303772.3303798. Kitto, Kirsty, and Simon Knight. 2019. “Practical Ethics for Building Learning Analytics.” British Journal of Educational Technology 50 (6): 2855–70. https://doi.org/10.1111/bjet.12868. Kizilcec, René F, Mar Pérez-Sanagustín, and Jorge J Maldonado. 2017. “Self-Regulated Learning Strategies Predict Learner Behavior and Goal Attainment in Massive Open Online Courses.” Computers &amp; Education 104: 18–33. https://doi.org/10.1016/j.compedu.2016.10.001. Knight, Simon, and Simon Buckingham Shum. 2017. “Theory and Learning Analytics.” In Handbook of Learning Analytics, 17–22. SoLAR. Krumm, Andrew, Barbara Means, and Marie Bienkowski. 2018. Learning Analytics Goes to School: A Collaborative Approach to Improving Education. Routledge. Perrotta, Carlo, and Ben Williamson. 2018. “The Social Life of Learning Analytics: Cluster Analysis and the ‘Performance’ of Algorithmic Education.” Learning, Media and Technology 43 (1): 3–16. https://doi.org/10.1080/17439884.2016.1182927. Prinsloo, Paul, and Sharon Slade. 2017. “Ethics and Learning Analytics: Charting the (Un)Charted.” In Handbook of Learning Analytics, edited by Charles Lang, George Siemens, Alyssa Wise, and Dragan Gasevic, First, 49–57. Society for Learning Analytics Research (SoLAR). https://doi.org/10.18608/hla17.004. Romero, Cristobal, and Sebastian Ventura. 2020. “Educational Data Mining and Learning Analytics: An Updated Survey.” WIREs Data Mining and Knowledge Discovery 10 (3). https://doi.org/10.1002/widm.1355. Siemens, George. 2013. “Learning Analytics: The Emergence of a Discipline.” The American Behavioral Scientist 57 (10): 1380–1400. Slater, Stefan, Srećko Joksimović, Vitomir Kovanovic, Ryan S Baker, and Dragan Gasevic. 2017. “Tools for Educational Data Mining: A Review.” Journal of Educational and Behavioral Statistics: A Quarterly Publication Sponsored by the American Educational Research Association and the American Statistical Association 42 (1): 85–106. https://doi.org/10.3102/1076998616666808. Winne, Philip H. 2017. “Learning Analytics for Self-Regulated Learning.” In Handbook of Learning Analytics, edited by Charles Lang, George Siemens, Alyssa Wise, and Dragan Gasevic, First, 241–49. Society for Learning Analytics Research (SoLAR). https://doi.org/10.18608/hla17.021. Wise, Alyssa Friend, and David Williamson Schaffer. 2015. “Why Theory Matters More Than Ever in the Age of Big Data.” Journal of Learning Analytics 2 (2): 5–13. https://doi.org/10.18608/jla.2015.22.2. "]
]
